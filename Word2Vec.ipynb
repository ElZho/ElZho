{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPwm3bb8F32JFLjO9hF/Yo0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElZho/ElZho/blob/main/Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "XIvTFeHg_lZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/ODS/Text.txt', encoding='utf-8') as file:\n",
        "    contents = file.read()"
      ],
      "metadata": {
        "id": "r7EEmYQ8DWm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " file.close"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXmX9Q88FgTU",
        "outputId": "81d5ad38-3b88-4906-8c08-58f195ba73c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function TextIOWrapper.close>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contents=contents.lower()\n",
        "text=contents.replace(r'\\,', '')\n",
        "text=contents.replace(r\"\\’\", \"\")\n",
        "text=contents.replace(r\"\\.\", \"\")\n",
        "text=contents.replace(r\"\\W\", \" \")\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "5X_BezVfFy4c",
        "outputId": "792adc6c-4dd6-47dd-c2d8-ab628840c97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ufeffsustainable supermarkets\\nmany of the major supermarket chains have come under fire with accusations of various unethical acts over the past decade. they’ve wasted tonnes of food, they’ve underpaid their suppliers and they’ve contributed to excessive plastic waste in their packaging, which has had its impact on our environment.\\nbut supermarkets and grocers are starting to sit up and take notice. in response to growing consumer backlash against the huge amounts of plastic waste generated by plastic packaging, some of the largest uk supermarkets have signed up to a pact promising to transform packaging and cut plastic wastage. in a pledge to reuse, recycle or compost all plastic wastage by 2025, supermarkets are now beginning to take some responsibility for the part they play in contributing to the damage to our environment, with one major supermarket announcing their plan to eliminate all plastic packaging in their own-brand products by 2023.\\nin response to criticisms over food waste, some supermarkets are donating some of their food surplus. however, charities estimate that they are only accessing two per cent of supermarkets’ total food surplus, so this hardly seems to be solving the problem. some say that supermarkets are simply not doing enough. most supermarkets operate under a veil of secrecy when asked for exact figures of food wastage, and without more transparency it is hard to come up with a systematic approach to avoiding waste and to redistributing surplus food.\\nsome smaller companies are now taking matters into their own hands and offering consumers a greener, more environmentally friendly option. shops like berlin’s original unverpakt and london’s bulk market are plastic-free shops that have opened in recent years, encouraging customers to use their own containers or compostable bags. online grocer farmdrop eliminates the need for large warehouses and the risk of huge food surplus by delivering fresh produce from local farmers to its customers on a daily basis via electric cars, offering farmers the lion’s share of the retail price.\\nthere is no doubt that we still have a long way to go in reducing food waste and plastic waste. but perhaps the major supermarkets might take inspiration from these smaller grocers and gradually move towards a more sustainable future for us all.\\na threat to bananas\\nin the 1950s, central american commercial banana growers were facing the death of their most lucrative product, the gros michel banana, known as big mike. and now it’s happening again to big mike’s successor – the cavendish.\\nwith its easily transported, thick-skinned and sweet-tasting fruit, the gros michel banana plant dominated the plantations of central america. united fruit, the main grower and exporter in south america at the time, mass-produced its bananas in the most efficient way possible: it cloned shoots from the stems of plants instead of growing plants from seeds, and cultivated them in densely packed fields.\\nunfortunately, these conditions are also perfect for the spread of the fungus fusarium oxysporum f. sp. cubense, which attacks the plant’s roots and prevents it from transporting water to the stem and leaves. the tr-1 strain of the fungus was resistant to crop sprays and travelled around on boots or the tyres of trucks, slowly infecting plantations across the region. in an attempt to escape the fungus, farmers abandoned infected fields, flooded them and then replanted crops somewhere else, often cutting down rainforest to do so.\\ntheir efforts failed. so, instead, they searched for a variety of banana that the fungus didn’t affect. they found the cavendish, as it was called, in the greenhouse of a british duke. it wasn’t as well suited to shipping as the gros michel, but its bananas tasted good enough to keep consumers happy. most importantly, tr-1 didn’t seem to affect it. in a few years, united fruit had saved itself from bankruptcy by filling its plantations with thousands of the new plants, copying the same monoculture growing conditions gros michel had thrived in.\\nwhile the operation was a huge success for the latin american industry, the cavendish banana itself is far from safe. in 2014, south east asia, another major banana producer, exported four million tons of cavendish bananas. but, in 2015, its exports had dropped by 46 per cent thanks to a combination of another strain of the fungus, tr-4, and bad weather.\\ngrowing practices in south east asia haven’t helped matters. growers can’t always afford the expensive lab-based methods to clone plants from shoots without spreading the disease. also, they often aren’t strict enough about cleaning farm equipment and quarantining infected fields. as a result, the fungus has spread to australia, the middle east and mozambique – and latin america, heavily dependent on its monoculture cavendish crops, could easily be next.\\nracing against the inevitable, scientists are working on solving the problem by genetically modifying the cavendish with genes from tr-4-resistant banana species. researchers at the queensland university of technology have successfully grown two kinds of modified plant which have remained resistant for three years so far. but some experts think this is just a sophisticated version of the same temporary solution the original cavendish provided. if the new bananas are planted in the same monocultures as the cavendish and the gros michel before it, the risk is that another strain of the disease may rise up to threaten the modified plants too.'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def W_2_v(data):\n",
        "  import torch\n",
        "  from torch import nn\n",
        "  from torch.autograd import Variable\n",
        "  import torch.nn.functional as F\n",
        "  # from collections import defaultdict\n",
        "  import numpy as np  \n",
        "  import random\n",
        "\n",
        "  data=data.split()\n",
        "  len_t=len(data)\n",
        "  vocabulary = set(data)\n",
        "  v_size = len(vocabulary)  \n",
        "  word2idx={w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "  w_z=2\n",
        "  l_r=0.01\n",
        "  epochs=100\n",
        "  emb_dims=12             \n",
        "        \n",
        "  def get_pairs(data, w_z, len_t, word2idx ):\n",
        "      pairs=[]\n",
        "      for i1, w1 in enumerate(data): \n",
        "        i2_beg = max(0, i1-w_z)\n",
        "        for i2 in range(i2_beg, min(len_t, i1+w_z+1) ):            \n",
        "          if i2 != i1: \n",
        "            pairs.append((w1, data[i2])) \n",
        "      \n",
        "      random_seed = 342     \n",
        "      random.shuffle(pairs)\n",
        "         \n",
        "\n",
        "      X = np.zeros((len(pairs), 1),   dtype=np.int64)\n",
        "      Y = np.zeros((len(pairs)),      dtype=np.int64) \n",
        "      for i, (u,w) in enumerate(pairs):        \n",
        "        X[i,0] = word2idx[u]\n",
        "        Y[i]   = word2idx[w]      \n",
        "      return X, Y  \n",
        "\n",
        "      \n",
        "  def get_weights(v_size, data, word2idx, len_t): \n",
        "        idf = np.zeros( (v_size,), dtype=np.float32)            \n",
        "        for i, w in enumerate(data):                                             \n",
        "          idf[word2idx[w]] += 1            \n",
        "        idf = ( 1+np.log(len_t/(idf+1), dtype=np.float32) )\n",
        "        return idf*(v_size/idf.sum())        \n",
        "\n",
        "  class SkipGram(nn.Module):\n",
        "      def __init__(self, V_DIM, E_DIM): \n",
        "          super(SkipGram, self).__init__()           \n",
        "          self.emb1 = nn.Embedding(V_DIM, E_DIM, scale_grad_by_freq=True) \n",
        "          self.flat = nn.Flatten()\n",
        "          self.linear=nn.Linear(E_DIM, V_DIM, bias=False)   \n",
        "      def forward(self, x):\n",
        "          out=self.emb1(x)\n",
        "          out=self.flat(out)\n",
        "          out=self.linear(out)\n",
        "          return out\n",
        "  def train(X, Y, model, optimizer, criterion, epochs):               \n",
        "      loss_list = np.zeros((epochs,))   \n",
        "\n",
        "      for epo in range(epochs):        \n",
        "        for it in range(0, len(X), 16):          \n",
        "          xb = torch.from_numpy( X[it: it+16] ).to(device)\n",
        "          yb = torch.from_numpy( Y[it: it+16] ).to(device)\n",
        "          \n",
        "          model.train()\n",
        "          y = model(xb)\n",
        "          loss = criterion(y, yb)          \n",
        "          loss_list[epo] += np.sum(loss.detach().cpu().numpy())                \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # scheduler.step(loss) \n",
        "        # loss_list[epo] = loss.item()  \n",
        "        # loss_list[epo] /= (len(X)/16)              \n",
        "      #   if epo % 5 == 0:                  \n",
        "      #         print(f'Loss at epo {epo}: {loss.item()}')              \n",
        "      # print(f'Loss at epo {epo}: {loss.item()}')  \n",
        "      E = model.emb1.weight              \n",
        "      W = model.linear.weight              \n",
        "      new_E = 0.5*(model.emb1.weight+model.linear.weight)             \n",
        "      return  new_E #0.5*(model.emb1.weight+model.linear.weight)   \n",
        "  def make_dict(Emb, word2idx):\n",
        "    d={}\n",
        "    for word, val in word2idx.items():\n",
        "      emb = Emb[val]         \n",
        "      d.update({word:emb.detach().numpy() })\n",
        "    return d \n",
        "  \n",
        "  \n",
        "  if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "  else:    \n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "  X, Y= get_pairs(data, w_z, len_t, word2idx )\n",
        "  weights= get_weights(v_size, data, word2idx, len_t)\n",
        "  # print(l_r, emb_dims, epochs)\n",
        "  \n",
        "\n",
        "  model= SkipGram(v_size, emb_dims).to(device) \n",
        "      \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=l_r)\n",
        "  # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\\\n",
        "  #                           factor=0.95, threshold=0.1, min_lr=0.01, verbose=True)\n",
        "          \n",
        "  criterion = nn.CrossEntropyLoss(torch.tensor(weights)) \n",
        "  \n",
        "  Embeding=train(X, Y, model, optimizer, criterion, epochs)\n",
        "  \n",
        "  \n",
        "  return make_dict(Embeding, word2idx)"
      ],
      "metadata": {
        "id": "rXCkzOa47-sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "d1=W_2_v(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWju30Ne0Cr3",
        "outputId": "98ff2480-1fb3-4da1-a2b8-63c6b1e5eb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 12.3 s, sys: 28 ms, total: 12.3 s\n",
            "Wall time: 12.4 s\n"
          ]
        }
      ]
    }
  ]
}